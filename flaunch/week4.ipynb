{"cells":[{"cell_type":"markdown","metadata":{"id":"vuf9VLidt7-y"},"source":["# **-->Mental Health Chatbot<--**\n"]},{"cell_type":"markdown","metadata":{"id":"UdtYBPaRchYJ"},"source":["### 1. Requirments"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ZOzy8lH1x1RK","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"7134f0af-f256-4482-b62a-ab530c00674d","executionInfo":{"status":"ok","timestamp":1729014569347,"user_tz":-330,"elapsed":19348,"user":{"displayName":"ved patil","userId":"13951098826152422498"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit\n","  Downloading streamlit-1.39.0-py2.py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Collecting huggingface\n","  Downloading huggingface-0.0.1-py3-none-any.whl.metadata (2.9 kB)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Collecting deep_translator\n","  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n","Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting peft\n","  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n","Collecting bitsandbytes\n","  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n","Collecting asyncio\n","  Downloading asyncio-3.4.3-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n","Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n","Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (16.1.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.2)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n","Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n","  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n","Collecting watchdog<6,>=2.1.5 (from streamlit)\n","  Downloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep_translator) (4.12.3)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.34.2)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.6)\n","Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n","  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.4.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n","  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.1)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Downloading streamlit-1.39.0-py2.py3-none-any.whl (8.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n","Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m935.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading asyncio-3.4.3-py3-none-any.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.8/101.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=49ffc111a30a17120d43c56e64498b1b0951549c04cae581ade915eb063e9ab8\n","  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n","Successfully built wget\n","Installing collected packages: wget, huggingface, asyncio, watchdog, smmap, pydeck, gitdb, deep_translator, gitpython, bitsandbytes, streamlit, peft\n","Successfully installed asyncio-3.4.3 bitsandbytes-0.44.1 deep_translator-1.11.4 gitdb-4.0.11 gitpython-3.1.43 huggingface-0.0.1 peft-0.13.2 pydeck-0.9.1 smmap-5.0.1 streamlit-1.39.0 watchdog-5.0.3 wget-3.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["asyncio"]},"id":"51a7b7034ba2438b80d7a8d600a096a8"}},"metadata":{}}],"source":["!pip install streamlit textblob pandas huggingface pillow transformers deep_translator wget peft bitsandbytes asyncio"]},{"cell_type":"markdown","metadata":{"id":"jsTHnsnDchYK"},"source":["### 2. Model Download"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"p0CUBgBbl0CY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"273f32d6-5046-4982-f821-49184ee25dd7","executionInfo":{"status":"ok","timestamp":1729014632181,"user_tz":-330,"elapsed":62838,"user":{"displayName":"ved patil","userId":"13951098826152422498"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Llama-3.2-1B-Instruct'...\n","remote: Enumerating objects: 31, done.\u001b[K\n","remote: Counting objects: 100% (28/28), done.\u001b[K\n","remote: Compressing objects: 100% (28/28), done.\u001b[K\n","remote: Total 31 (delta 9), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n","Unpacking objects: 100% (31/31), 2.24 MiB | 2.44 MiB/s, done.\n"]}],"source":["! git clone https://huggingface.co/unsloth/Llama-3.2-1B-Instruct"]},{"cell_type":"markdown","source":["### **download Dataset**"],"metadata":{"id":"y6sw6xaJMmDW"}},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uf8pbXg8chYL","outputId":"e48fc107-ad10-4e42-91c2-a947234b81bd","executionInfo":{"status":"ok","timestamp":1729014643881,"user_tz":-330,"elapsed":11703,"user":{"displayName":"ved patil","userId":"13951098826152422498"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-10-15 17:50:31--  https://docs.google.com/uc?export=download&id=1qf0zh7YwXVSCNBxnRGmUD7GMMuEipiJ5\n","Resolving docs.google.com (docs.google.com)... 108.177.119.139, 108.177.119.138, 108.177.119.113, ...\n","Connecting to docs.google.com (docs.google.com)|108.177.119.139|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://drive.usercontent.google.com/download?id=1qf0zh7YwXVSCNBxnRGmUD7GMMuEipiJ5&export=download [following]\n","--2024-10-15 17:50:31--  https://drive.usercontent.google.com/download?id=1qf0zh7YwXVSCNBxnRGmUD7GMMuEipiJ5&export=download\n","Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.250.153.132, 2a00:1450:4013:c16::84\n","Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.250.153.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4790520 (4.6M) [application/octet-stream]\n","Saving to: ‘mentalhealth-1.json’\n","\n","mentalhealth-1.json 100%[===================>]   4.57M  --.-KB/s    in 0.06s   \n","\n","2024-10-15 17:50:43 (81.9 MB/s) - ‘mentalhealth-1.json’ saved [4790520/4790520]\n","\n"]}],"source":["! wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1qf0zh7YwXVSCNBxnRGmUD7GMMuEipiJ5' -O mentalhealth-1.json"]},{"cell_type":"markdown","metadata":{"id":"hyp7irr_chYL"},"source":["### 3. Code of main APP"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4WidjC86qfb6","outputId":"ec026788-a549-4f83-a5a2-13248111e134","executionInfo":{"status":"ok","timestamp":1729014643881,"user_tz":-330,"elapsed":4,"user":{"displayName":"ved patil","userId":"13951098826152422498"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing app.py\n"]}],"source":["%%writefile app.py\n","import streamlit as st\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n","from peft import LoraConfig, get_peft_model, PeftModel\n","import torch\n","from torch.utils.data import Dataset\n","from textblob import TextBlob\n","from deep_translator import GoogleTranslator\n","import asyncio\n","import pandas as pd\n","import plotly.express as px\n","from datetime import datetime\n","from typing import Dict, List, Any\n","import os\n","\n","# Define the TRANSLATIONS dictionary (unchanged)\n","TRANSLATIONS = {\n","    \"English\": {\n","        \"main_title\": \"Mental Health Chatbot\",\n","        \"initial_question\": \"Hello! How are you feeling today?\",\n","        \"input_placeholder\": \"Type your message here...\",\n","        \"thinking\": \"Thinking...\",\n","        \"how_feeling\": \"How are you feeling?\",\n","        \"log_mood\": \"Log Mood\",\n","        \"mood_logged\": \"Mood logged successfully!\",\n","        \"mood_over_time\": \"Mood Over Time\",\n","        \"your_name\": \"Your Name\",\n","        \"your_age\": \"Your Age\",\n","        \"your_interests\": \"Your Interests\",\n","        \"preferred_topics\": \"Preferred Topics\",\n","        \"about_chatbot\": \"About This Chatbot\",\n","        \"chatbot_description\": \"This chatbot is designed to provide mental health support...\",\n","        \"disclaimer\": \"Disclaimer: This chatbot is not a substitute for professional medical advice...\",\n","        \"crisis_response\": \"I'm concerned about what you've shared. Please reach out to a mental health professional or crisis helpline immediately.\",\n","        \"recommended_resources\": \"Recommended Resources\",\n","        \"footer\": \"© 2024 Mental Health Chatbot. All rights reserved.\",\n","        \"personalization\": \"Personalization\",\n","        \"mood_tracking\": \"Mood Tracking\",\n","        \"settings\": \"Settings\",\n","        \"select_language\": \"Select Response Language\",\n","        \"fine_tuning\": \"Fine-tuning\",\n","        \"fine_tune_button\": \"Fine-tune Model\",\n","        \"fine_tune_success\": \"Model fine-tuned successfully! Restart the app to use the fine-tuned model.\"\n","    }\n","    # Add translations for other languages here\n","}\n","\n","\n","@st.cache_resource\n","def load_model(model_name=\"Llama-3.2-1B-Instruct\"):\n","    try:\n","        with st.spinner(\"Loading model. This may take a moment...\"):\n","            tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","            if torch.cuda.is_available():\n","                st.info(\"CUDA is available. Loading model on GPU.\")\n","                model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map=\"auto\")\n","            else:\n","                st.warning(\"CUDA is not available. Loading model on CPU. This may be slower.\")\n","                model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n","\n","        st.success(\"Model loaded successfully!\")\n","        return tokenizer, model\n","    except Exception as e:\n","        st.error(f\"Error loading model: {str(e)}\")\n","        return None, None\n","class MentalHealthStructuredDataset(torch.utils.data.Dataset):\n","    def __init__(self, data, tokenizer, max_length=512):\n","        self.data = data\n","        self.tokenizer = tokenizer\n","        self.max_length = max_length\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        row = self.data.iloc[index]\n","\n","        # Create input and target text using the conversational context and response\n","        input_text = f\"Context: {row['Context']}\"\n","        target_text = f\"Response: {row['Response']}\"\n","\n","        # Tokenize the input and response texts\n","        inputs = self.tokenizer(\n","            input_text,\n","            truncation=True,\n","            max_length=self.max_length,\n","            padding=\"max_length\",\n","            return_tensors=\"pt\"\n","        )\n","\n","        targets = self.tokenizer(\n","            target_text,\n","            truncation=True,\n","            max_length=self.max_length,\n","            padding=\"max_length\",\n","            return_tensors=\"pt\"\n","        )\n","\n","        labels = targets[\"input_ids\"].clone()\n","        labels[labels == self.tokenizer.pad_token_id] = -100  # Ignore padding tokens in loss calculation\n","\n","        return {\n","            'input_ids': inputs['input_ids'].flatten(),\n","            'attention_mask': inputs['attention_mask'].flatten(),\n","            'labels': labels.flatten()\n","        }\n","\n","\n","\n","def fine_tune_model(model, tokenizer, train_data, output_dir=\"./fine_tuned_model\"):\n","    print(train_data.head())  # Debug print\n","    print(train_data.columns)  # Debug print\n","\n","    # Set pad_token to eos_token if not already defined\n","    if tokenizer.pad_token is None:\n","        tokenizer.pad_token = tokenizer.eos_token\n","\n","    # Manually specify target modules for Llama model\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n","\n","    lora_config = LoraConfig(\n","        r=16,\n","        lora_alpha=32,\n","        target_modules=target_modules,\n","        lora_dropout=0.05,\n","        bias=\"none\",\n","        task_type=\"CAUSAL_LM\"\n","    )\n","\n","    model = get_peft_model(model, lora_config)\n","\n","    training_args = TrainingArguments(\n","        output_dir=output_dir,\n","        num_train_epochs=3,\n","        per_device_train_batch_size=4,\n","        warmup_steps=500,\n","        learning_rate=3e-4,\n","        fp16=True,\n","        logging_steps=10,\n","        save_strategy=\"epoch\",\n","    )\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=MentalHealthStructuredDataset(train_data, tokenizer, max_length=512),\n","    )\n","\n","    trainer.train()\n","    model.save_pretrained(output_dir)\n","@st.cache_data\n","def generate_text(_tokenizer, _model, prompt: str, max_new_tokens: int = 150) -> str:\n","    try:\n","        inputs = _tokenizer(prompt, return_tensors=\"pt\").to(_model.device)\n","        with torch.no_grad():\n","            outputs = _model.generate(**inputs, max_new_tokens=max_new_tokens, temperature=0.7, top_p=0.9)\n","        response = _tokenizer.decode(outputs[0], skip_special_tokens=True)\n","        return response[len(prompt):].strip()\n","    except Exception as e:\n","        st.error(f\"Error generating text: {str(e)}\")\n","        return \"I'm sorry, I encountered an error while processing your request.\"\n","\n","@st.cache_data\n","def analyze_sentiment(text: str) -> float:\n","    blob = TextBlob(text)\n","    return blob.sentiment.polarity\n","\n","@st.cache_data\n","def translate_text(text: str, target_language: str) -> str:\n","    try:\n","        translator = GoogleTranslator(source='auto', target=target_language)\n","        return translator.translate(text)\n","    except Exception as e:\n","        st.error(f\"Translation error: {str(e)}\")\n","        return text\n","\n","def translate_content(content: Dict[str, str], target_language: str) -> Dict[str, str]:\n","    if target_language == \"English\":\n","        return content\n","    translator = GoogleTranslator(source='en', target=target_language)\n","    return {k: translator.translate(v) for k, v in content.items()}\n","\n","def get_translated_content(language: str) -> Dict[str, str]:\n","    if language not in TRANSLATIONS:\n","        content = TRANSLATIONS[\"English\"]\n","        return translate_content(content, language)\n","    return TRANSLATIONS[language]\n","\n","async def run_parallel(*functions):\n","    return await asyncio.gather(*[asyncio.to_thread(func) for func in functions])\n","\n","def track_mood(t: Dict[str, str]):\n","    if 'mood_history' not in st.session_state:\n","        st.session_state.mood_history = []\n","\n","    mood = st.multiselect(t[\"how_feeling\"], [\"Sad\", \"Happy\", \"Angry\", \"Anxious\", \"Feared\"])\n","    if st.button(t[\"log_mood\"]):\n","        st.session_state.mood_history.append({\n","            'date': datetime.now().strftime(\"%Y-%m-%d\"),\n","            'mood': mood\n","        })\n","        st.success(t[\"mood_logged\"])\n","\n","    if st.session_state.mood_history:\n","        df = pd.DataFrame(st.session_state.mood_history)\n","        fig = px.line(df, x='date', y='mood', title=t[\"mood_over_time\"])\n","        st.plotly_chart(fig)\n","\n","def personalize_chatbot(t: Dict[str, str]) -> Dict[str, Any]:\n","    if 'user_preferences' not in st.session_state:\n","        st.session_state.user_preferences = {\n","            'name': '',\n","            'age': '',\n","            'interests': [],\n","            'preferred_topics': []\n","        }\n","\n","    st.session_state.user_preferences['name'] = st.text_input(t[\"your_name\"], st.session_state.user_preferences['name'])\n","    st.session_state.user_preferences['age'] = st.number_input(t[\"your_age\"], min_value=0, max_value=120, value=st.session_state.user_preferences['age'] if st.session_state.user_preferences['age'] else 0)\n","    interests = st.multiselect(t[\"your_interests\"], [\"Reading\", \"Music\", \"Sports\", \"Art\", \"Travel\", \"Technology\"], default=st.session_state.user_preferences['interests'])\n","    st.session_state.user_preferences['interests'] = interests\n","    topics = st.multiselect(t[\"preferred_topics\"], [\"Stress Management\", \"Positive Thinking\", \"Mindfulness\", \"Relationship Advice\", \"Career Guidance\"], default=st.session_state.user_preferences['preferred_topics'])\n","    st.session_state.user_preferences['preferred_topics'] = topics\n","\n","    return st.session_state.user_preferences\n","\n","def recommend_resources(sentiment: float) -> List[str]:\n","    resources = {\n","        \"positive\": [\n","            \"Mindfulness meditation app\",\n","            \"Gratitude journaling guide\",\n","            \"Positive affirmations list\"\n","        ],\n","        \"neutral\": [\n","            \"Self-care checklist\",\n","            \"Stress management techniques\",\n","            \"Healthy habit tracker\"\n","        ],\n","        \"negative\": [\n","            \"Crisis helpline numbers\",\n","            \"Therapy finder tool\",\n","            \"Coping strategies for difficult emotions\"\n","        ]\n","    }\n","\n","    if sentiment > 0.2:\n","        category = \"positive\"\n","    elif sentiment < -0.2:\n","        category = \"negative\"\n","    else:\n","        category = \"neutral\"\n","\n","    return resources[category]\n","\n","def detect_crisis(text: str) -> bool:\n","    crisis_keywords = [\"suicide\", \"kill myself\", \"want to die\", \"end it all\"]\n","    return any(keyword in text.lower() for keyword in crisis_keywords)\n","\n","def run_app():\n","    st.set_page_config(page_title=\"Mental Health Chatbot\", page_icon=\"🤖\", layout=\"wide\")\n","\n","    # Initialize translations in session state\n","    if 'translations' not in st.session_state:\n","        st.session_state.translations = TRANSLATIONS[\"English\"]\n","\n","    tokenizer, base_model = load_model()\n","    if tokenizer is None or base_model is None:\n","        st.error(\"Failed to load the model. Please check the error message above and try again.\")\n","        st.stop()\n","\n","    # Check if a fine-tuned model exists\n","    fine_tuned_model_path = \"./fine_tuned_model\"\n","    if os.path.exists(fine_tuned_model_path):\n","        st.info(\"Loading fine-tuned model...\")\n","        model = PeftModel.from_pretrained(base_model, fine_tuned_model_path)\n","        st.success(\"Fine-tuned model loaded successfully!\")\n","    else:\n","        model = base_model\n","        st.warning(\"No fine-tuned model found. Using base model.\")\n","\n","    with st.sidebar:\n","        st.title(st.session_state.translations[\"settings\"])\n","        language = st.selectbox(st.session_state.translations[\"select_language\"], [\"English\", \"Hindi\", \"Gujarati\", \"Marathi\"])\n","        language_code = {\"English\": \"en\", \"Hindi\": \"hi\", \"Gujarati\": \"gu\", \"Marathi\": \"mr\"}[language]\n","\n","        if 'language' not in st.session_state or st.session_state.language != language:\n","            st.session_state.language = language\n","            st.session_state.translations = get_translated_content(language_code)\n","            st.rerun()\n","\n","        t = st.session_state.translations\n","\n","        st.divider()\n","        st.subheader(t[\"personalization\"])\n","        user_preferences = personalize_chatbot(t)\n","        st.divider()\n","        st.subheader(t[\"mood_tracking\"])\n","        track_mood(t)\n","        st.divider()\n","        st.write(t[\"about_chatbot\"])\n","        st.write(t[\"chatbot_description\"])\n","        st.write(t[\"disclaimer\"])\n","\n","        # Add fine-tuning option\n","        st.divider()\n","        st.subheader(t[\"fine_tuning\"])\n","        if st.button(t[\"fine_tune_button\"]):\n","            train_data = pd.read_json('mentalhealth-1.json', lines=True)\n","            fine_tune_model(base_model, tokenizer, train_data)\n","            st.success(t[\"fine_tune_success\"])\n","\n","    st.title(t[\"main_title\"])\n","\n","    if 'messages' not in st.session_state:\n","        st.session_state.messages = []\n","    if 'conversation_started' not in st.session_state:\n","        st.session_state.conversation_started = False\n","\n","    if not st.session_state.conversation_started:\n","        initial_question = t[\"initial_question\"]\n","        st.session_state.messages.append({\"role\": \"assistant\", \"content\": initial_question})\n","        st.session_state.conversation_started = True\n","\n","    for message in st.session_state.messages:\n","        with st.chat_message(message[\"role\"]):\n","            st.markdown(message[\"content\"])\n","\n","    user_input = st.chat_input(t[\"input_placeholder\"])\n","\n","    if user_input:\n","        st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n","        with st.chat_message(\"user\"):\n","            st.markdown(user_input)\n","\n","        loop = asyncio.new_event_loop()\n","        asyncio.set_event_loop(loop)\n","        user_input_en, sentiment_score = loop.run_until_complete(run_parallel(\n","            lambda: translate_text(user_input, 'en') if language != \"English\" else user_input,\n","            lambda: analyze_sentiment(user_input)\n","        ))\n","\n","        sentiment = \"positive\" if sentiment_score > 0 else \"neutral\" if sentiment_score == 0 else \"negative\"\n","\n","        if detect_crisis(user_input_en):\n","            crisis_response = t[\"crisis_response\"]\n","            st.session_state.messages.append({\"role\": \"assistant\", \"content\": crisis_response})\n","            with st.chat_message(\"assistant\"):\n","                st.markdown(crisis_response)\n","            st.stop()\n","\n","        formatted_history = \"\\n\".join(\n","            f\"{'Assistant' if msg['role'] == 'assistant' else 'Human'}: {msg['content']}\"\n","            for msg in st.session_state.messages[-5:]\n","        )\n","\n","        response_prompt = f\"\"\"You are a compassionate AI assistant dedicated to supporting mental well-being. Based on the conversation history and the user's current sentiment, craft a thoughtful response that addresses the user's input and provides support. Then, ask a follow-up question to encourage further discussion.\n","\n","User Information:\n","Name: {user_preferences['name']}\n","Age: {user_preferences['age']}\n","Interests: {', '.join(user_preferences['interests'])}\n","Preferred Topics: {', '.join(user_preferences['preferred_topics'])}\n","\n","Conversation History:\n","{formatted_history}\n","\n","User's Input:\n","Human: {user_input_en}\n","\n","Detected Sentiment: {sentiment}\n","\n","Your Response with emoji and Follow-up Question:\n","Assistant:\"\"\"\n","        with st.spinner(t[\"thinking\"]):\n","            response_en = generate_text(tokenizer, model, response_prompt)\n","            response = translate_text(response_en, language_code) if language != \"English\" else response_en\n","            st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n","\n","            with st.chat_message(\"assistant\"):\n","                st.markdown(response)\n","\n","            resources = recommend_resources(sentiment_score)\n","            st.subheader(t[\"recommended_resources\"])\n","            for resource in resources:\n","                st.write(f\"- {resource}\")\n","\n","    st.markdown('</div>', unsafe_allow_html=True)\n","    st.markdown(\"---\")\n","    st.markdown(t[\"footer\"])\n","\n","if __name__ == \"__main__\":\n","    run_app()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3bC6dyWcchYM"},"source":["### 4. To run App on Google Colab"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"knmARhCwqi_F","outputId":"b35ea05e-9fc6-4c46-abea-0f9410604599","executionInfo":{"status":"ok","timestamp":1729014643881,"user_tz":-330,"elapsed":3,"user":{"displayName":"ved patil","userId":"13951098826152422498"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["34.32.171.79\n"]}],"source":["!wget -q -O - ipv4.icanhazip.com"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p6piHO9Xrzxy","outputId":"ebbe0a64-3e7d-4085-b37d-b62e04b92ef5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n","\u001b[0m\n","\u001b[1G\u001b[0JNeed to install the following packages:\n","  localtunnel@2.0.2\n","Ok to proceed? (y) \u001b[20G\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.32.171.79:8501\u001b[0m\n","\u001b[0m\n","y\n","\u001b[K\u001b[?25hyour url is: https://quiet-parrots-hang.loca.lt\n","2024-10-15 17:51:33.455435: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-10-15 17:51:33.801985: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-10-15 17:51:33.896765: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-10-15 17:51:34.483035: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-10-15 17:51:35.921264: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["# prompt: start streamlit app\n","\n","! streamlit run /content/app.py & npx localtunnel --port 8501"]},{"cell_type":"markdown","metadata":{"id":"FE3JtYehchYM"},"source":["### 4. To run App on Device"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"mp4W6UgvchYM","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1729014533938,"user_tz":-330,"elapsed":1789,"user":{"displayName":"ved patil","userId":"13951098826152422498"}},"outputId":"4162fdea-043e-47a5-b007-6e814467e799"},"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: streamlit: command not found\n"]}],"source":["! streamlit run app.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vXTP9EQZchYN"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6U9l7yKxchYN"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}